{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "isCoaPsw13PL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k7yDdFAATD5",
    "outputId": "1fd34c8f-e637-4c9e-ab5f-0d6c9712fa00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VNPmN0u_2CQh"
   },
   "outputs": [],
   "source": [
    "input_path = \"C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(), #for parallel computations\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "#train_subset_size = int(0.4 * len(datasets.ImageFolder(input_path + 'lisat_gaze_data_v1/train', transform=data_transforms['train']))) #testing hashelha b3den\n",
    "#val_subset_size = int(0.4 * len(datasets.ImageFolder(input_path + 'lisat_gaze_data_v1/val', transform=data_transforms['validation'])))\n",
    "image_datasets = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(input_path + 'lisat_gaze_data_v1/train', data_transforms['train']),\n",
    "    'validation':\n",
    "    datasets.ImageFolder(input_path + 'lisat_gaze_data_v1/val', data_transforms['validation'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sq056PqWBILr",
    "outputId": "7644d8c5-777d-482a-b71c-8c8aa4d7a55b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AS-GP\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AS-GP\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =torchvision.models.mobilenet_v2(pretrained=True).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_l7PyhiCJq3",
    "outputId": "fb97bfc9-8e6d-4b9e-f2d3-915aba69ef54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=8, bias=True)\n",
       "    (2): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =torchvision.models.mobilenet_v2(pretrained=True).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=1280, out_features=8, bias=True),\n",
    "            nn.Softmax(dim=1))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bdresbWBCjr9"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.classifier.parameters())\n",
    "# Define the grid of hyperparameters\n",
    "batch_sizes = [16, 32, 64]\n",
    "learning_rates = [0.0001, 0.001, 0.1]\n",
    "weight_decays = [0.0001, 0.001, 0.01]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_size, learning_rate , weight_decay , train_loader, test_loader):\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        best_val_accuracy =0;\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train().to(device) #added to device\n",
    "                data_loader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                data_loader = test_loader\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "\n",
    "            \n",
    "            for data, target in data_loader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(output, 1)\n",
    "                running_loss += loss.item() * data.size(0)\n",
    "                running_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "\n",
    "            if(phase == 'validation' and epoch_acc > best_val_accuracy):\n",
    "                    best_val_accuracy = epoch_acc\n",
    "            \n",
    "    return best_val_accuracy\n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 16, Learning rate: 0.0001, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.9418, acc: 0.3574\n",
      "validation loss: 1.8664, acc: 0.4664\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.8285, acc: 0.5205\n",
      "validation loss: 1.7791, acc: 0.5431\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.7838, acc: 0.5549\n",
      "validation loss: 1.7373, acc: 0.6083\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.7580, acc: 0.5732\n",
      "validation loss: 1.7261, acc: 0.6139\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.7261, acc: 0.6076\n",
      "validation loss: 1.7188, acc: 0.6060\n",
      "Current Best accuracy: 0.6059726254666113\n",
      "Current Best parameters: (16, 0.0001, 0.0001)\n",
      "Batch size: 16, Learning rate: 0.0001, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.7115, acc: 0.6168\n",
      "validation loss: 1.7106, acc: 0.6012\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.6964, acc: 0.6297\n",
      "validation loss: 1.7114, acc: 0.5954\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.6890, acc: 0.6334\n",
      "validation loss: 1.6996, acc: 0.6147\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.6822, acc: 0.6352\n",
      "validation loss: 1.7068, acc: 0.5977\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.6791, acc: 0.6352\n",
      "validation loss: 1.6806, acc: 0.6240\n",
      "Current Best accuracy: 0.6240149315636665\n",
      "Current Best parameters: (16, 0.0001, 0.001)\n",
      "Batch size: 16, Learning rate: 0.0001, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.6743, acc: 0.6481\n",
      "validation loss: 1.6916, acc: 0.6180\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.6802, acc: 0.6490\n",
      "validation loss: 1.6984, acc: 0.6201\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.6856, acc: 0.6487\n",
      "validation loss: 1.7094, acc: 0.6116\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.6894, acc: 0.6476\n",
      "validation loss: 1.7067, acc: 0.6296\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.6943, acc: 0.6498\n",
      "validation loss: 1.7027, acc: 0.6365\n",
      "Current Best accuracy: 0.6364579012857735\n",
      "Current Best parameters: (16, 0.0001, 0.01)\n",
      "Batch size: 16, Learning rate: 0.001, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.6760, acc: 0.6319\n",
      "validation loss: 1.7352, acc: 0.5288\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.6438, acc: 0.6475\n",
      "validation loss: 1.6774, acc: 0.6020\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.6295, acc: 0.6576\n",
      "validation loss: 1.7023, acc: 0.5734\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.6194, acc: 0.6664\n",
      "validation loss: 1.6484, acc: 0.6323\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.6137, acc: 0.6670\n",
      "validation loss: 1.7194, acc: 0.5545\n",
      "Batch size: 16, Learning rate: 0.001, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.6116, acc: 0.6696\n",
      "validation loss: 1.6592, acc: 0.6182\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.6142, acc: 0.6701\n",
      "validation loss: 1.7037, acc: 0.5664\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.6155, acc: 0.6718\n",
      "validation loss: 1.6681, acc: 0.6114\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.6212, acc: 0.6663\n",
      "validation loss: 1.7331, acc: 0.5371\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.6164, acc: 0.6724\n",
      "validation loss: 1.7061, acc: 0.5674\n",
      "Batch size: 16, Learning rate: 0.001, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.6669, acc: 0.6475\n",
      "validation loss: 1.7420, acc: 0.5496\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.7117, acc: 0.6170\n",
      "validation loss: 1.7401, acc: 0.5564\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.7168, acc: 0.6114\n",
      "validation loss: 1.6993, acc: 0.6184\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.7142, acc: 0.6183\n",
      "validation loss: 1.7264, acc: 0.5985\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.7163, acc: 0.6083\n",
      "validation loss: 1.7052, acc: 0.6178\n",
      "Batch size: 16, Learning rate: 0.1, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1333, acc: 0.1408\n",
      "validation loss: 2.0430, acc: 0.2310\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1458, acc: 0.1281\n",
      "validation loss: 2.1562, acc: 0.1178\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.1199, acc: 0.1540\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 2.1319, acc: 0.1420\n",
      "validation loss: 2.0430, acc: 0.2310\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1441, acc: 0.1298\n",
      "validation loss: 2.2130, acc: 0.0610\n",
      "Batch size: 16, Learning rate: 0.1, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1506, acc: 0.1229\n",
      "validation loss: 2.1896, acc: 0.0844\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1379, acc: 0.1357\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.1226, acc: 0.1508\n",
      "validation loss: 2.1282, acc: 0.1458\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 2.1434, acc: 0.1300\n",
      "validation loss: 2.1218, acc: 0.1387\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1434, acc: 0.1301\n",
      "validation loss: 2.1896, acc: 0.0844\n",
      "Batch size: 16, Learning rate: 0.1, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1386, acc: 0.1339\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1297, acc: 0.1427\n",
      "validation loss: 2.1685, acc: 0.1056\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.1310, acc: 0.1414\n",
      "validation loss: 2.1685, acc: 0.1056\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 2.1308, acc: 0.1418\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1463, acc: 0.1262\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Batch size: 32, Learning rate: 0.0001, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1551, acc: 0.1189\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1551, acc: 0.1189\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.0644, acc: 0.2179\n",
      "validation loss: 1.8637, acc: 0.4714\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.8463, acc: 0.4825\n",
      "validation loss: 1.8010, acc: 0.5079\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.8075, acc: 0.5110\n",
      "validation loss: 1.7907, acc: 0.5048\n",
      "Batch size: 32, Learning rate: 0.0001, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.7855, acc: 0.5313\n",
      "validation loss: 1.7893, acc: 0.4971\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.7690, acc: 0.5495\n",
      "validation loss: 1.7784, acc: 0.5058\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.7601, acc: 0.5532\n",
      "validation loss: 1.7642, acc: 0.5216\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.7494, acc: 0.5623\n",
      "validation loss: 1.7663, acc: 0.5089\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.7331, acc: 0.5818\n",
      "validation loss: 1.7367, acc: 0.5651\n",
      "Batch size: 32, Learning rate: 0.0001, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.7203, acc: 0.6016\n",
      "validation loss: 1.7223, acc: 0.5925\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.7155, acc: 0.6107\n",
      "validation loss: 1.7135, acc: 0.6054\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.7133, acc: 0.6163\n",
      "validation loss: 1.7212, acc: 0.6010\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.7128, acc: 0.6190\n",
      "validation loss: 1.7020, acc: 0.6309\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.7127, acc: 0.6222\n",
      "validation loss: 1.7191, acc: 0.6033\n",
      "Batch size: 32, Learning rate: 0.001, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.6937, acc: 0.6129\n",
      "validation loss: 1.6890, acc: 0.6039\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.6638, acc: 0.6294\n",
      "validation loss: 1.6993, acc: 0.5827\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.6566, acc: 0.6305\n",
      "validation loss: 1.6782, acc: 0.6039\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.6466, acc: 0.6384\n",
      "validation loss: 1.6798, acc: 0.5985\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.6433, acc: 0.6413\n",
      "validation loss: 1.6652, acc: 0.6120\n",
      "Batch size: 32, Learning rate: 0.001, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.6422, acc: 0.6429\n",
      "validation loss: 1.6752, acc: 0.6064\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.6444, acc: 0.6413\n",
      "validation loss: 1.6673, acc: 0.6182\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.6450, acc: 0.6402\n",
      "validation loss: 1.6615, acc: 0.6242\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.6465, acc: 0.6390\n",
      "validation loss: 1.6875, acc: 0.5942\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.6443, acc: 0.6439\n",
      "validation loss: 1.6928, acc: 0.5840\n",
      "Batch size: 32, Learning rate: 0.001, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.6768, acc: 0.6325\n",
      "validation loss: 1.7084, acc: 0.6155\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.7126, acc: 0.6113\n",
      "validation loss: 1.7117, acc: 0.6097\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.7178, acc: 0.6100\n",
      "validation loss: 1.7192, acc: 0.5867\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.7195, acc: 0.6084\n",
      "validation loss: 1.7475, acc: 0.5377\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.7216, acc: 0.6043\n",
      "validation loss: 1.7074, acc: 0.6051\n",
      "Batch size: 32, Learning rate: 0.1, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1162, acc: 0.1578\n",
      "validation loss: 2.1282, acc: 0.1458\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1288, acc: 0.1451\n",
      "validation loss: 2.2130, acc: 0.0610\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.1540, acc: 0.1199\n",
      "validation loss: 2.1685, acc: 0.1056\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.1337, acc: 0.1401\n",
      "validation loss: 2.0430, acc: 0.2310\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1301, acc: 0.1439\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Batch size: 32, Learning rate: 0.1, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1348, acc: 0.1387\n",
      "validation loss: 2.1850, acc: 0.0890\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1448, acc: 0.1288\n",
      "validation loss: 2.0430, acc: 0.2310\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.1206, acc: 0.1530\n",
      "validation loss: 2.1850, acc: 0.0890\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 2.1283, acc: 0.1450\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1263, acc: 0.1472\n",
      "validation loss: 2.1270, acc: 0.1439\n",
      "Batch size: 32, Learning rate: 0.1, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1433, acc: 0.1287\n",
      "validation loss: 2.1685, acc: 0.1056\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1450, acc: 0.1270\n",
      "validation loss: 2.1850, acc: 0.0890\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.1423, acc: 0.1298\n",
      "validation loss: 2.1850, acc: 0.0890\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 2.1431, acc: 0.1291\n",
      "validation loss: 2.0430, acc: 0.2310\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1534, acc: 0.1186\n",
      "validation loss: 2.1562, acc: 0.1178\n",
      "Batch size: 64, Learning rate: 0.0001, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.0436, acc: 0.2244\n",
      "validation loss: 1.9938, acc: 0.2640\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.9303, acc: 0.3532\n",
      "validation loss: 1.9352, acc: 0.3364\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.8870, acc: 0.4084\n",
      "validation loss: 1.8982, acc: 0.3687\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.8589, acc: 0.4422\n",
      "validation loss: 1.8867, acc: 0.3774\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.8430, acc: 0.4597\n",
      "validation loss: 1.8759, acc: 0.3843\n",
      "Batch size: 64, Learning rate: 0.0001, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.8308, acc: 0.4688\n",
      "validation loss: 1.8733, acc: 0.3857\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.8208, acc: 0.4796\n",
      "validation loss: 1.8666, acc: 0.3915\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.8151, acc: 0.4830\n",
      "validation loss: 1.8651, acc: 0.3932\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.8108, acc: 0.4864\n",
      "validation loss: 1.8678, acc: 0.3868\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.8027, acc: 0.4944\n",
      "validation loss: 1.8652, acc: 0.3911\n",
      "Batch size: 64, Learning rate: 0.0001, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.8037, acc: 0.4935\n",
      "validation loss: 1.8605, acc: 0.3973\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.7997, acc: 0.5014\n",
      "validation loss: 1.8562, acc: 0.4048\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.8009, acc: 0.5020\n",
      "validation loss: 1.8605, acc: 0.3971\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.8022, acc: 0.5020\n",
      "validation loss: 1.8608, acc: 0.3988\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.8010, acc: 0.5049\n",
      "validation loss: 1.8603, acc: 0.4002\n",
      "Batch size: 64, Learning rate: 0.001, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.7585, acc: 0.5464\n",
      "validation loss: 1.7863, acc: 0.4996\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.7133, acc: 0.5828\n",
      "validation loss: 1.7867, acc: 0.4884\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.6976, acc: 0.5953\n",
      "validation loss: 1.7622, acc: 0.5116\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.6929, acc: 0.5949\n",
      "validation loss: 1.7715, acc: 0.5064\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.6887, acc: 0.5972\n",
      "validation loss: 1.7630, acc: 0.5085\n",
      "Batch size: 64, Learning rate: 0.001, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.6858, acc: 0.6007\n",
      "validation loss: 1.7567, acc: 0.5187\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.6852, acc: 0.6014\n",
      "validation loss: 1.7799, acc: 0.4876\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.6873, acc: 0.5986\n",
      "validation loss: 1.7831, acc: 0.4878\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.6856, acc: 0.6019\n",
      "validation loss: 1.7642, acc: 0.5073\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.6841, acc: 0.6041\n",
      "validation loss: 1.7768, acc: 0.4965\n",
      "Batch size: 64, Learning rate: 0.001, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 1.7017, acc: 0.5989\n",
      "validation loss: 1.7866, acc: 0.5027\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 1.7337, acc: 0.5848\n",
      "validation loss: 1.7994, acc: 0.4913\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 1.7403, acc: 0.5827\n",
      "validation loss: 1.8043, acc: 0.4921\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 1.7424, acc: 0.5788\n",
      "validation loss: 1.7958, acc: 0.4975\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 1.7441, acc: 0.5777\n",
      "validation loss: 1.7938, acc: 0.4884\n",
      "Batch size: 64, Learning rate: 0.1, Weight decay: 0.0001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1033, acc: 0.1706\n",
      "validation loss: 2.2130, acc: 0.0610\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1643, acc: 0.1096\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.0891, acc: 0.1848\n",
      "validation loss: 2.1562, acc: 0.1178\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 2.1054, acc: 0.1684\n",
      "validation loss: 2.1685, acc: 0.1056\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1298, acc: 0.1441\n",
      "validation loss: 2.1562, acc: 0.1178\n",
      "Batch size: 64, Learning rate: 0.1, Weight decay: 0.001\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1159, acc: 0.1577\n",
      "validation loss: 2.0430, acc: 0.2310\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1417, acc: 0.1318\n",
      "validation loss: 2.2130, acc: 0.0610\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.1302, acc: 0.1432\n",
      "validation loss: 2.0430, acc: 0.2310\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 2.1459, acc: 0.1277\n",
      "validation loss: 2.1565, acc: 0.1168\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1109, acc: 0.1624\n",
      "validation loss: 2.1562, acc: 0.1178\n",
      "Batch size: 64, Learning rate: 0.1, Weight decay: 0.01\n",
      "Epoch 1/5\n",
      "----------\n",
      "train loss: 2.1297, acc: 0.1424\n",
      "validation loss: 2.1085, acc: 0.1655\n",
      "Epoch 2/5\n",
      "----------\n",
      "train loss: 2.1353, acc: 0.1365\n",
      "validation loss: 2.0340, acc: 0.2312\n",
      "Epoch 3/5\n",
      "----------\n",
      "train loss: 2.1430, acc: 0.1292\n",
      "validation loss: 2.2130, acc: 0.0610\n",
      "Epoch 4/5\n",
      "----------\n",
      "train loss: 2.1152, acc: 0.1572\n",
      "validation loss: 2.0617, acc: 0.2267\n",
      "Epoch 5/5\n",
      "----------\n",
      "train loss: 2.1467, acc: 0.1260\n",
      "validation loss: 2.1896, acc: 0.0844\n",
      " Final Best parameters: (16, 0.0001, 0.01)\n",
      "Final Best accuracy: 0.6364579012857735\n"
     ]
    }
   ],
   "source": [
    "# Perform the grid search\n",
    "best_parameters = ()\n",
    "best_accuracy = 0.0\n",
    "for batch_size in batch_sizes:\n",
    "    for learning_rate in learning_rates:\n",
    "        for weight_decay in weight_decays:\n",
    "            print(f\"Batch size: {batch_size}, Learning rate: {learning_rate}, Weight decay: {weight_decay}\")\n",
    "            train_loader = torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True)\n",
    "            test_loader = torch.utils.data.DataLoader(image_datasets['validation'], batch_size=batch_size, shuffle=False)\n",
    "            accuracy = train_and_evaluate(batch_size, learning_rate, weight_decay , train_loader , test_loader)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_parameters = (batch_size, learning_rate, weight_decay)\n",
    "                print(f\"Current Best accuracy: {best_accuracy}\")\n",
    "                print(f\"Current Best parameters: {best_parameters}\")\n",
    "\n",
    "print(f\" Final Best parameters: {best_parameters}\")\n",
    "print(f\"Final Best accuracy: {best_accuracy}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
